{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_Recommender.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "TRveDJI3_Xau",
        "colab_type": "code",
        "outputId": "b1a232da-8deb-407d-9aac-503f6654ec8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "#loading dataset file from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v3-uSABB_xmW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip \"/content/gdrive/My Drive/data_csv.zip\"\n",
        "# !unzip \"/content/gdrive/My Drive/challenge_set.zip\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NH74X60qWe5E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#installing spark and java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.3.3/spark-2.3.3-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.3.3-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f8SgE9-lW0Yh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#locating spark and java\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.3-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C7eq3nX0JdFJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import StorageLevel\n",
        "spark = SparkSession.builder.appName('music recommendation system').config(\"spark.driver.memory\",\"15g\").config(\"spark.executor.memory\",\"15g\").getOrCreate()\n",
        "df=spark.read.format(\"csv\").option(\"header\", \"true\").load(\"*.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oiMXqjZsz0C5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T66lmtBXJdFn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from pyspark import SparkConf,SparkContext\n",
        "# conf = SparkConf()\n",
        "# sc = SparkContext(conf=conf)\n",
        "# pickleRdd = sparkpickle('dataframe').collect()\n",
        "# df = spark.createDataFrame(pickleRdd)\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import lit\n",
        "from pyspark.sql.functions import col\n",
        "# Adding the rating column \n",
        "all_data = df.select(\"trackid\",\"artist_name\",\"track_name\", \"pid\").withColumn(\"rating\", lit(1))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "M-wy8LbMJdFx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer,StringIndexerModel\n",
        "# stringIndexer = StringIndexer(inputCol=\"trackid\", outputCol=\"songid\", handleInvalid=\"error\",stringOrderType='frequencyDesc')\n",
        "# model = stringIndexer.fit(all_data)\n",
        "model=StringIndexerModel.load('/content/gdrive/My Drive/stringindexmodel.h5')\n",
        "df = model.transform(all_data)\n",
        "#df.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nBbxP50uCkES",
        "colab_type": "code",
        "outputId": "15948357-be0c-4193-a585-7a6da390e3be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "all_data.unpersist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[trackid: string, artist_name: string, track_name: string, pid: string, rating: int]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "XuOiBggBFCD-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "df= df.withColumn(\"songid1\", df[\"songid\"].cast(IntegerType()))\n",
        "df=df.withColumn(\"pid1\",df[\"pid\"].cast(IntegerType()))\n",
        "train, test = df.randomSplit([0.9, 0.1], seed = 2019)\n",
        "# print(\"Training Dataset Count: \" + str(train.count()))\n",
        "# print(\"Test Dataset Count: \" + str(test.count()))\n",
        "#rating_df.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R782wiCYJdF7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rating_df=train.select(\"pid1\",\"songid1\",\"rating\").filter(train.pid1.isNotNull())\n",
        "test=test.select(\"pid1\",\"songid1\",\"rating\").filter(test.pid1.isNotNull())\n",
        "# df=df.select(\"pid1\",\"songid1\",\"rating\").filter(df.pid1.isNotNull())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "49EtzBU1JdF_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##TRAINING AND SAVING MODEL\n",
        "from pyspark.ml.recommendation import ALS\n",
        "als=ALS(rank=5,maxIter=50,regParam=0.2,implicitPrefs=True, userCol=\"pid1\", itemCol=\"songid1\", ratingCol=\"rating\",\n",
        "          coldStartStrategy=\"drop\")\n",
        "model=als.fit(rating_df)\n",
        "model.save('/content/gdrive/My Drive/ALSmodel2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Q6ooRd3JdGE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#LOADING MODEL\n",
        "from pyspark.ml.recommendation import ALSModel\n",
        "model = ALSModel.load('/content/gdrive/My Drive/ALSmodel1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4_JTE5KgJdGJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#RECOMMEND FOR TEST DATASET\n",
        "# user_subset = rating_df.where(rating_df.pid1<100000 )\n",
        "userRecs = model.recommendForUserSubset(test, 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0tqRep1CJdGT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode\n",
        "top_k=userRecs.withColumn(\"Recommendations\", explode(userRecs.recommendations))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "duk7l1dDJdGY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "top_k=top_k.select('pid1', 'Recommendations.*')\n",
        "top_k=top_k.select('pid1','songid1')\n",
        "# top_k.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sMIA-2FsJdGe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import DoubleType\n",
        "top_k= top_k.withColumn(\"songid1\", top_k[\"songid1\"].cast(DoubleType()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iWHpPxsJJdGl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# df.createOrReplaceTempView(\"dataframe\")\n",
        "train.createOrReplaceTempView(\"dataframe\")\n",
        "top_k.createOrReplaceTempView(\"results\")\n",
        "df2 = spark.sql(\"SELECT dataframe.songid,dataframe.track_name,dataframe.artist_name from dataframe where dataframe.songid IN(SELECT results.songid1 from results)\").persist(StorageLevel.DISK_ONLY)\n",
        "spark.catalog.dropTempView(\"dataframe\")\n",
        "spark.catalog.dropTempView(\"results\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fOL_3H0CJdGr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "final=top_k.join(df2,top_k.songid1==df2.songid).dropDuplicates()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I0ltRr-MJdGx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "final=final.select(\"pid1\",\"track_name\",\"artist_name\").withColumnRenamed(\"track_name\", \"Recommendation\").orderBy('pid1')\n",
        "# final.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ye836IafR6U1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# df3=df.select(\"pid1\",\"track_name\",\"artist_name\")\n",
        "df3=df.select(\"pid1\",\"track_name\",\"artist_name\").filter(df.pid1.isNotNull()).orderBy(\"pid1\")\n",
        "\n",
        "#selecting pid 0 to 99999 for evaluation\n",
        "# df3=df3.where(df3.pid1<100000)\n",
        "#df3.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Br7KklmzOMh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as f\n",
        "final=final.groupBy(f.col('pid1')).agg(f.collect_set('Recommendation').alias('Recommendation'),f.collect_set('artist_name').alias('Rartist_name'))\n",
        "# itcount=topk.select('*',f.size('Recommendation').alias('track_intersection'),f.size('artist_name').alias('artist_intersection'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j2Jo3KLR6OTR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df3=df3.groupBy(f.col('pid1')).agg(f.collect_set('track_name').alias('track_name'),f.collect_set('artist_name').alias('artist_name'))\n",
        "# gt=counts.select('*',f.size('track_name').alias('track_count'),f.size('artist_name').alias('artist_count'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v2viIoUk7b8c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df3.createOrReplaceTempView(\"t1\")\n",
        "final.createOrReplaceTempView(\"t2\")\n",
        "temp = spark.sql(\"SELECT t1.pid1,t1.track_name,t1.artist_name,t2.Recommendation,t2.Rartist_name from t1,t2 where t1.pid1==t2.pid1\")\n",
        "spark.catalog.dropTempView(\"t1\")\n",
        "spark.catalog.dropTempView(\"t2\")\n",
        "# temp=final.join(df3,\"pid1\").persist(StorageLevel.DISK_ONLY)\n",
        "\n",
        "# .withColumn('Rprecision_track',(f.col('track_intersection') / f.col('track_count')))\n",
        "# res=temp.withColumn('Rprecision_artist',(f.col('artist_intersection')/f.col('artist_count')))\n",
        "# temp.take(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d8JntTKgQybA",
        "colab_type": "code",
        "outputId": "c9f9fc27-d8e0-4b03-e892-ca07efc4c4ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from pyspark.mllib.evaluation import RankingMetrics\n",
        "#NDCG SCORE\n",
        "rddtrack=temp.rdd.map(lambda x:(x[1],x[3]))\n",
        "metrics=RankingMetrics(rddtrack)\n",
        "metrics.ndcgAt(100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06814588324799176"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "TpZ7TMmyz49s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Mean Average Precision\n",
        "metrics.meanAveragePrecision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mQ08oFI9k6tN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#R-Precision- Logic one\n",
        "!pip install pyarrow\n",
        "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
        "topk1=topk.toPandas()\n",
        "original=df3.toPandas()\n",
        "\n",
        "import numpy as np\n",
        "def R_prec():\n",
        "  total=0\n",
        "  for i in range(100000):\n",
        "    d=len(original[original['pid1']==i])\n",
        "    it=np.intersect1d(topk1[topk1['pid1']==i]['Recommendation'],original[original['pid1']==i]['track_name'])\n",
        "    it1=np.intersect1d(topk1[topk1['pid1']==i]['artist_name'],original[original['pid1']==i]['artist_name'])\n",
        "    n=len(it)/d\n",
        "    n1=len(it1)/d\n",
        "    total+=n+0.25*n1\n",
        "  return (total/100000)\n",
        "rp=R_prec()\n",
        "rp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cCa5XSvFkXQ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#R-Precision- Logic 2\n",
        "counts=df3.groupBy(col('pid1')).count()\n",
        "import numpy as np\n",
        "def R_prec():\n",
        "  n=0\n",
        "  n1=0\n",
        "  for i in range(3000):\n",
        "    num=counts.select(\"count\").where(counts.pid1==i).collect()[0]['count']\n",
        "    Gt=[row.track_name for row in df3.select('track_name').where(df3.pid1==i).collect()]\n",
        "    Ga=[row.artist_name for row in df3.select('artist_name').where(df3.pid1==i).collect()]\n",
        "    Rt=[row.Recommendation for row in topk.select('Recommendation').where(topk.pid1==i).collect()]\n",
        "    Ra=[row.artist_name for row in topk.select('artist_name').where(topk.pid1==i).collect()]\n",
        "    it=np.intersect1d(Rt,Gt)\n",
        "    it1=np.intersect1d(Ra,Ga)\n",
        "    n=len(it)/num\n",
        "    n1=len(it1)/num\n",
        "    yield (n+0.25*n1)\n",
        "rp=[j for j in R_prec()]\n",
        "np.mean(rp) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m3VdAoQZk33t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#R-precision-Logic 3\n",
        "counts=temp.groupBy(col('pid1')).count()\n",
        "import numpy as np\n",
        "pid=[row.pid1 for row in temp.select('pid1').collect()]\n",
        "def Rprec():\n",
        "  for i in pid:\n",
        "    num=counts.select(\"count\").where(counts.pid1==i).collect()[0]['count']\n",
        "    it=np.intersect1d(temp.select('Recommendation').where(temp.pid1==i).collect(),temp.select('track_name').where(temp.pid1==i).collect())\n",
        "    it1=np.intersect1d(temp.select('Rartist_name').where(temp.pid1==i).collect(),temp.select('artist_name').where(temp.pid1==i).collect())\n",
        "    n=len(it)/num\n",
        "    n1=len(it1)/num\n",
        "    yield (n+0.25*n1)\n",
        "rp=[j for j in Rprec()]\n",
        "np.mean(rp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sMRMFyV5RVQm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# Gt=[(row.pid1,row.track_name,row.artist_name) for row in df3.collect()]\n",
        "# Rt=[(row.pid1,row.Recommendation,row.artist_name) for row in topk.collect()]\n",
        "# # Gtruth= pd.DataFrame(Gt,columns=['pid','track_name','artist_name'])\n",
        "# # reco=pd.DataFrame(Rt,columns=['pid','Recommendation','artist_name'])\n",
        "\n",
        "# def R_prec():\n",
        "#   n=0\n",
        "#   n1=0\n",
        "#   m=[]\n",
        "#   for i in range(200000):\n",
        "#     it=np.intersect1d(reco[reco['pid']==i]['Recommendation'],Gtruth[Gtruth['pid']==i]['track_name'])\n",
        "#     it1=np.intersect1d(reco[reco['pid']==i]['artist_name'],Gtruth[Gtruth['pid']==i]['artist_name'])\n",
        "#     n=len(it)/len(Gtruth[Gtruth['pid']==i])\n",
        "#     n1=len(it1)/len(Gtruth[Gtruth['pid']==i])\n",
        "#     m.append(n+0.25*n1)\n",
        "#   return m\n",
        "# rp=R_prec()\n",
        "# np.mean(rp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W1ptgd2Lrgk8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Jyl8PeXymaI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from pyspark.sql import functions as F\n",
        "# df4=df3.groupby(\"pid1\").agg(F.collect_set(\"track_name\").alias(\"track_name\"),F.collect_set(\"artist_name\").alias(\"artist_name\"))\n",
        "# topk1=topk.groupby(\"pid1\").agg(F.collect_set(\"Recommendation\").alias(\"Recommendation\"),F.collect_set(\"artist_name\").alias(\"artist_name\"))\n",
        "# counts=df3.groupBy(col('pid1')).count()\n",
        "# def R_prec():\n",
        "#   n=0\n",
        "#   n1=0\n",
        "#   for i in range(1000):\n",
        "#     num=counts.where(counts.pid1==i).collect()[0]['count']\n",
        "#     it=np.intersect1d(topk1.where(topk1.pid1==0).collect()[0]['Recommendation'],df4.where(df4.pid1==0).collect()[0]['track_name'])\n",
        "#     it1=np.intersect1d(topk1.where(topk1.pid1==0).collect()[0]['artist_name'],df4.where(df4.pid1==0).collect()[0]['artist_name'])\n",
        "#     n=len(it)/num\n",
        "#     n1=len(it1)/num\n",
        "#     yield (n+0.25*n1)\n",
        "# rp=[]\n",
        "# rprec=R_prec()\n",
        "# for i in rprec:\n",
        "#   rp.append(i)\n",
        "# np.mean(rp) \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OiujCM-tGgHW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#R-precision - logic 4(optimized)\n",
        "!pip install handyspark\n",
        "from handyspark import *\n",
        "from pyspark.sql import functions as F\n",
        "import numpy as np\n",
        "recommended=temp.toHandy()\n",
        "\n",
        "def Rprec():\n",
        "  for i,j,k,l in zip(recommended.cols['Recommendation'][:],recommended.cols['track_name'][:],recommended.cols['Rartist_name'][:],recommended.cols['artist_name'][:]):\n",
        "    it=np.intersect1d(i,j)\n",
        "    it1=np.intersect1d(k,l)\n",
        "    yield ((len(it)+0.25*len(it1))/len(j))\n",
        "rp=[r for r in Rprec()]\n",
        "np.mean(rp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OYaXKjj0ONx1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cz57KCmuZjtg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P8qDs9WWnMxU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}